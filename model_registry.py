# LLM_MODELS = {
#     "llama3_8b": "meta-llama/Meta-Llama-3-8B-Instruct",
#     "mixtral_8x7b": "mistralai/Mixtral-8x7B-Instruct-v0.1",
#     "mistral_7b": "mistralai/Mistral-7B-Instruct-v0.2",
#     "qwen_14b": "Qwen/Qwen1.5-14B-Chat",
#     "gemma_7b": "google/gemma-7b-it"
# }

LLM_MODELS = {
    "llama3_8b": "meta-llama/Meta-Llama-3.1-8B-Instruct", # Updated to 3.1 
    # "mixtral_8x7b": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "mistral_7b": "mistralai/Mistral-7B-Instruct-v0.3",   # Updated to v0.3
    "qwen_14b": "Qwen/Qwen2.5-14B-Instruct",               # Updated to Qwen2
    "gemma_7b": "google/gemma-2-9b-it"                  # Updated to Gemma 2
}
